# Predicci√≥n del tr√°fico de Madrid con LSTM

La direcci√≥n de GitHub para este repositorio es la siguiente: [Repositorio](https://github.com/lauralardies/Madrid-traffic-Prediction-with-LSTM).

## √çndice

- [üî∞ Introducci√≥n](#-introducci√≥n)
- [üßÆ Datos](#-datos)
- [üóÉÔ∏è Archivos](#-archivos)
- [üöÄ Ejecuci√≥n](#-ejecuci√≥n)

## üî∞ Introducci√≥n

En este proyecto se trata de predecir el tr√°fico de Madrid, modelando una red neuronal LSTM, arquitectura capaz de captar patrones temporales a partir de secuencias de datos. Se hace esto con el objetivo de reducir las congestiones, reduciendo tambi√©n por lo tanto las emisiones y mejorando la calidad de vida de los ciudadanos. A partir del modelo entrenado, se realizan predicciones, las cuales facilitar√°n la generaci√≥n una red de carreteras con intensidades (valores predichos) asignadas a los nodos. Y ya por √∫ltimo, se calcula el camino m√≠nimo mediante el algoritmo de Dijkstra, mundialmente conocido y con un costo computacional bajo, adem√°s de estimar el tiempo del trayecto bas√°ndose en la distancia recorrida (se calcula la distancia euclidea entre dos puntos) y la velocidad media (valor que tambi√©n predice el modelo). 

En el repositorio actual se pueden encontrar varios cuadernos de Jupyter con Python y Markdown que, celda por celda, van desarrollando todo el proceso descrito.

## üßÆ Datos

Para entrenar un modelo para que prediga el tr√°fico, se necesita acceso a los siguientes datos:

- Un historial de datos de tr√°fico de Madrid, a partir de los cuales el modelo aprender√° e identificar√° patrones para predecir el tr√°fico correctamente.
- Datos en tiempo real que se emplean para realizar simulaciones de hora de llegada estimada y recomendaciones de horas de salida a partir de una hora de llegada dada.

> ¬øDe d√≥nde se obtienen los datos? Para este estudio, se recopilaron datos desde el [portal de datos abiertos del Ayuntamiento de Madrid](https://datos.madrid.es/portal/site/egob), m√°s concretamente, el [hist√≥rico de datos de tr√°fico desde 2013](https://datos.madrid.es/sites/v/index.jsp?vgnextoid=33cb30c367e78410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD) y los [datos del tr√°fico en tiempo real](https://datos.madrid.es/sites/v/index.jsp?vgnextoid=02f2c23866b93410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD), pero no han sido adjuntados en este repositorio debido a su gran volumen.

## üóÉÔ∏è Archivos

El repositorio est√° organizado de la siguiente manera:

- Una carpeta general, desde la cual se puede acceder a el c√≥dio completo laldama `Traffic`.
- Una carpeta llamada `models` donde se encuentran las cuatro distintas variaciones de modelos desarrollados a lo largo del estudio: `lstm.ipynb` para la red m√°s b√°sica, `lstm2.ipynb` para una red algo m√°s compleja, `lstm2_cyclical.ipynb` para la misma red anterior pero aplicando transformaciones sobre las variables c√≠clicas y `lstm_attention.ipynb` algo m√°s sencilla que la anterior (aplicando tambi√©n la transformaci√≥n sobre las variables c√≠clicas) e integrando en la red una capa de atenci√≥n.
- Una carpeta llamada `optimization` desde la cual se hacen todas las simulaciones de c√°lculo de camino m√≠nimo y estimaci√≥n de tiempo de trayecto. Se pueden encontrar dos archivos: `graph.ipynb` que se encarga de generar el grafo y actualizar sus intensidades seg√∫n los valores predichos, y `dijkstra.ipynb` que, a partir del grafo con intensidades, calcula el camino m√≠nimo y estima la hora de salida o llegada, seg√∫n el caso.
- Una carpeta llamada `predictions` que contiene tan solo un documento, `prediction.ipynb` que se encarga de cargar un modelo entrenado, hacer las predicciones correspondientes y guardarlas para su uso a posteriori.
- Una carpeta llamada `process data`, encargada de todo lo que tiene que ver sobre el an√°lisis de datos previo a todo el entrenamiento de modelos y predicciones. Se pueden unir los datos mensuales en un √∫nico CSV (`unite_data.ipynb`), visualizar los datos en un mapa (`map_data.ipynb`), generar gr√°ficas de los datos (`visualization.ipynb`) y separar los datos en dsitintos CSVs seg√∫n su identificador (`separate_data.ipynb`).

Todos estos archivos y documentos constituyen el c√≥digo generado para mi trabajo de fin de grado.

## üöÄ Ejecuci√≥n

Para que se ejecuten todos los archivos de c√≥digo correctamente, se debe seguir el siguiente flujo de proceso:

1. Descargar los datos del portal de datos abiertos del Ayuntamiento de Madrid y almacenarlos en una nueva carpeta llamada `data`, dentro de `Traffic`. Adem√°s, guardar los datos hist√≥ricos mensuales en otra carpeta dentro de `data` llamada `monthly data`.
2. Ejecutar el archivo `unite_data.ipynb` para unir en un √∫nico CSV las entradas mensuales de datos.
3. En caso de querer visualizar los datos, ejecutar `map_data.ipynb` y `visualization.ipynb`.
4. Para preparar los datos para entrenar modelos, ejecutar `separate_data.ipynb`, de esta manera se separan los datos seg√∫n identificadores.
5. Ejecutar cualquiera de los modelos que se deseen dentro de la carpeta `models`, pudiendo cambiar el conunto de datos de entrenamiento libremente para cada caso. El modelo y escalador se guardan autom√°ticamente en una carpeta llamada `saved`.
6. Antes de ejecutar el c√≥digo de `prediction.ipynb`, ejecutar un modelo para cada set de datos separados en el paso 4 y guardarlo en una carpeta llamada `final` dentro de `models`.
7. Cuando ya se tiene un modelo por cada punto seleccionado, se pueden realizar las predicciones de `prediction.ipynb`, obteniendo 3 archivos tipo `pkl`.
8. Una vez hechas las predicciones, se puede generar el grafo y asignarle intensidades, ejecutando el archivo `graph.ipynb` dentro de la carpeta `optimization`.
9. Con el grafo generado y con ponderaciones, se puede calcular el camino m√≠nimo ejecutando `dijkstra.ipynb`, donde tamb√©n se obtiene la estimaci√≥n de la duraci√≥n del trayecto.
