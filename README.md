# Predicci√≥n del tr√°fico de Madrid con LSTM

La direcci√≥n de GitHub para este repositorio es la siguiente: [GitHub](https://github.com/lauralardies/Madrid-traffic-Prediction-with-LSTM).

## √çndice

- [üî∞ Introducci√≥n](#introducci√≥n)
- [üßÆ Datos](#datos)
- [üóÉÔ∏è Archivos](#archivos)
- [üöÄ Ejecuci√≥n](#ejecuci√≥n)

## üî∞ Introducci√≥n

En este proyecto se trata de predecir el tr√°fico de Madrid, modelando una red neuronal LSTM, arquitectura capaz de captar patrones temporales a partir de secuencias de datos. Se hace esto con el objetivo de reducir las congestiones, reduciendo tambi√©n por lo tanto las emisiones y mejorando la calidad de vida de los ciudadanos. A partir del modelo entrenado, se realizan predicciones, las cuales facilitar√°n la generaci√≥n una red de carreteras con intensidades (valores predichos) asignadas a los nodos. Y ya por √∫ltimo, se calcula el camino m√≠nimo mediante el algoritmo de Dijkstra, mundialmente conocido y con un costo computacional bajo, adem√°s de estimar el tiempo del trayecto bas√°ndose en la distancia recorrida (se calcula la distancia euclidea entre dos puntos) y la velocidad media (valor que tambi√©n predice el modelo). En el repositorio actual se pueden encontrar varios cuadernos de Jupyter con Python y Markdown que, celda por celda, van desarrollando todo el proceso descrito.

## üßÆ Datos

Para entrenar un modelo para que prediga el tr√°fico, se necesita acceso a los siguientes datos:
- Un historial de datos de tr√°fico de Madrid, a partir de los cuales el modelo aprender√° e identificar√° patrones para predecir el tr√°fico correctamente.
- Datos en tiempo real que se emplean para realizar simulaciones de hora de llegada estimada y recomendaciones de horas de salida a partir de una hora de llegada dada.

> ¬øDe d√≥nde se obtienen los datos? Para este estudio, se recopilaron datos desde el [portal de datos abiertos del Ayuntamiento de Madrid](https://datos.madrid.es/portal/site/egob), m√°s concretamente, el [hist√≥rico de datos de tr√°fico desde 2013](https://datos.madrid.es/sites/v/index.jsp?vgnextoid=33cb30c367e78410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD) y los [datos del tr√°fico en tiempo real](https://datos.madrid.es/sites/v/index.jsp?vgnextoid=02f2c23866b93410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD), pero no han sido adjuntados en este repositorio debido a su gran volumen.

## üóÉÔ∏è Archivos

El repositorio est√° organizado de la siguiente manera:
- Una carpeta general, desde la cual se puede acceder a el c√≥dio completo laldama `Traffic`.
- Una carpeta llamada `models` donde se encuentran las cuatro distintas variaciones de modelos desarrollados a lo largo del estudio: `lstm.ipynb` para la red m√°s b√°sica, `lstm2.ipynb` para una red algo m√°s compleja, `lstm2_cyclical.ipynb` para la misma red anterior pero aplicando transformaciones sobre las variables c√≠clicas y `lstm_attention.ipynb` algo m√°s sencilla que la anterior (aplicando tambi√©n la transformaci√≥n sobre las variables c√≠clicas) e integrando en la red una capa de atenci√≥n.
- Una carpeta llamada `optimization` desde la cual se hacen todas las simulaciones de c√°lculo de camino m√≠nimo y estimaci√≥n de tiempo de trayecto. Se pueden encontrar dos archivos: `graph.ipynb` que se encarga de generar el grafo y actualizar sus intensidades seg√∫n los valores predichos, y `dijkstra.ipynb` que, a partir del grafo con intensidades, calcula el camino m√≠nimo y estima la hora de salida o llegada, seg√∫n el caso.
- Una carpeta llamada `predictions` que contiene tan solo un documento, `prediction.ipynb` que se encarga de cargar un modelo entrenado, hacer las predicciones correspondientes y guardarlas para su uso a posteriori.
- Una carpeta llamada `process data`, encargada de todo lo que tiene que ver sobre el an√°lisis de datos previo a todo el entrenamiento de modelos y predicciones. Se pueden unir los datos mensuales en un √∫nico CSV (`unite_data.ipynb`), visualizar los datos en un mapa (`map_data.ipynb`), generar gr√°ficas de los datos (`visualization.ipynb`) y separar los datos en dsitintos CSVs seg√∫n su identificador (`separate_data.ipynb`).
Todos estos archivos y docuemtnos constituyen el c√≥digo generado para mi trabajo de fin de grado.

## üöÄ Ejecuci√≥n

Para que se ejecuten todos los archivos de c√≥digo correctamente, se debe seguir el siguiente flujo de proceso:
1¬∫
2¬∫
...
